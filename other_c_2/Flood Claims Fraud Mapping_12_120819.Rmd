---
title: "Flood Claims Fraud Mapping"
author: "Christian Conroy"
date: "9/30/2019"
output: html_document
---

```{r setup, include=FALSE}
require(knitr)
# install.packages('tidyverse')
library(tidyverse)
library(ggplot2)
# install.packages('dplyr')
library(dplyr)
# install.packages('rvest')
library(rvest)
library(rgdal)
library(synthpop)
library(sf)
library(rgeos)
library(maptools)

opts_chunk$set(echo = TRUE)
options(digits = 3)
opts_knit$set(root.dir ="~/USDA/GIS")
```

```{r message = FALSE}
# Import in subset claims data 
claims <- read.csv("2019allclaims_moisture_floods.csv")
claims <- claims[claims$stateName == "NE",]
claims <- claims[claims$monthNum >= 3 & claims$monthNum <=5,]

# Create IDs for non-indexed vara
claims$coveragecode <- as.numeric(claims$coverage)
claims$stagecode <- as.numeric(claims$stage)

```

########################################################################################## Creating synthetic farm locations using real claims data 
##########################################################################################

# Merge in country centroid coordinates 

Note: Do not really need in the end as we have the US county shapefiles that we can subset to whatever state we want. 

Scrape the wikipedia table 

```{r message = FALSE}
url <- "https://en.wikipedia.org/wiki/User:Michael_J/County_table"
county_coords <- url %>%
  read_html() %>%
  html_node(xpath = '//*[@id="mw-content-text"]/div/table') %>%
  html_table(fill = TRUE)
```

Merge with County data 

```{r message = FALSE}
# Prep for merge - make sure county names match
claims$stateName <- as.character(claims$stateName)
claims$countyName <- trimws(claims$countyName)
claims$countyName <- as.character(claims$countyName)
```

```{r message = FALSE}
# Align column names and merge
colnames(county_coords)[4] <- c("countyName")
colnames(county_coords)[2] <- c("stateName")
claims_countycoords <- left_join(claims, county_coords, by = c("stateName","countyName"))

```

Write the updated csv

```{r message = FALSE}
write.csv(claims_countycoords, "claims_countycoords_100419.csv")
```

################### Creating Synthetic Farms/Farm Polygons ####################

Create and Export Nebraska County Shapefile to use as backdrop for synthetic farm polygons in visualizing software.  
```{r message = FALSE}
setwd("~/USDA/GIS")
countymap <- readOGR("US County Shapes/tl_2017_us_county.shp")
countymap_nebraska <- countymap[countymap$STATEFP == 31,]
writeSpatialShape(countymap_nebraska, "NebraskaShape")
```

Import in census tract shapefiles, merge with rural urban tract classifiers, and merge with claims shapefile to restrict syntehtic farm area generation within counties to only rural areas within those counties 

```{r}
# Import in Census Tract Data 
setwd("~/USDA/GIS")
Nebraska_tracts <- readOGR("Nebraska Tracts/tl_2018_31_tract.shp")
# Import in rural urban classifiers for Nebraska 
Nebraska_urbrur <- read.csv('ruca2010revised.csv', header = TRUE, stringsAsFactors = FALSE)
# Prep for merge
colnames(Nebraska_urbrur)[4] <- c("FullTractCode")
Nebraska_tracts@data$FullTractCode <- paste(as.character(Nebraska_tracts@data$STATEFP), as.character(Nebraska_tracts@data$COUNTYFP), as.character(Nebraska_tracts@data$TRACTCE), sep = "")
# Merge rural-urban classifiers to tracts
Nebraska_tracts <- sp::merge(Nebraska_tracts, Nebraska_urbrur, by = c('FullTractCode'), all.x = TRUE, all.y = FALSE)
# Subset to just rural tracts (Small towns and rural areas)
Nebraska_tracts_rural <- Nebraska_tracts[Nebraska_tracts$Primary.RUCA.Code.2010 >=2 & Nebraska_tracts$Primary.RUCA.Code.2010 <= 10,]
# Save and export to compare to claims counties
writeSpatialShape(Nebraska_tracts_rural, "NebRural4")

# Merge polygons by county
Nebraska_tracts_rural.union <- unionSpatialPolygons(Nebraska_tracts_rural, Nebraska_tracts_rural$State.County.FIPS.Code)

###### Convert SpatialPolygons to data frame
Nebraska_tracts_rural.df <- as(Nebraska_tracts_rural, "data.frame")
Nebraska_tracts_rural.df$ALAND <- as.numeric(Nebraska_tracts_rural.df$ALAND)
Nebraska_tracts_rural.df$AWATER <- as.numeric(Nebraska_tracts_rural.df$AWATER)
Nebraska_tracts_rural.df$Tract.Population..2010 <- as.numeric(Nebraska_tracts_rural.df$Tract.Population..2010)
Nebraska_tracts_rural.df$Land.Area..square.miles...2010 <- as.numeric(Nebraska_tracts_rural.df$Land.Area..square.miles...2010)

# Aggregate and sum desired data attributes by ID list
Nebraska_tracts_rural.df.agg <- aggregate(Nebraska_tracts_rural.df[, c(10:11, 19:20)], list(Nebraska_tracts_rural.df$State.County.FIPS.Code), sum)

row.names(Nebraska_tracts_rural.df.agg) <- as.character(Nebraska_tracts_rural.df.agg$Group.1)

# Reconvert back to SPDF
Nebraska_tracts_rural.shp.agg <- SpatialPolygonsDataFrame(Nebraska_tracts_rural.union, Nebraska_tracts_rural.df.agg)

# Merge back in county names
NebCountNames <- Nebraska_tracts_rural@data[,c(14,16)] %>%
  group_by(Select.County)
NebCountNames <- as.data.frame(NebCountNames)
NebCountNames <- distinct(NebCountNames)
NebCountNames$Select.County <- substr(NebCountNames$Select.County,1,nchar(NebCountNames$Select.County)-7)
colnames(Nebraska_tracts_rural.shp.agg@data)[1] <- c("State.County.FIPS.Code")

Nebraska_tracts_rural.shp.agg <- sp::merge(Nebraska_tracts_rural.shp.agg, NebCountNames, by = c('State.County.FIPS.Code'), all.x = TRUE, all.y = TRUE)

##### Now we merge the new rural shapefile with the claims data 
claims_countycoords_neb <- claims_countycoords[claims_countycoords$stateName == 'NE',]
# Note: This is just our original NE subset dataframe with the coordinates for each county added

# Merge Nebraska rural county shapefile to claims data - will need to adjust state, county alignment with full dataset
Nebraska_tracts_rural.shp.agg@data$Select.County <- as.character(Nebraska_tracts_rural.shp.agg@data$Select.County)
Nebraska_tracts_rural.shp.agg@data <- separate(Nebraska_tracts_rural.shp.agg@data, State.County.FIPS.Code, into = c("STATEFP", "County Fips"), sep = 2, remove = FALSE) 
View(Nebraska_tracts_rural.shp.agg@data)  
  
claims_countycoords_neb$countyName <- as.character(claims_countycoords_neb$countyName)
colnames(claims_countycoords_neb)[5] <- c("Select.County")
colnames(claims_countycoords_neb)[2] <- c("STATEFP")

# Just to check
nrow(claims_countycoords_neb)
length(unique(claims_countycoords_neb$NAME))
# 1036 claims in 88 counties

# Merge to give each claim an associated county polygon
claims_withshapes_ruralsub <- sp::merge(Nebraska_tracts_rural.shp.agg, claims_countycoords_neb, by = c('STATEFP','Select.County'), all.x = FALSE, all.y = TRUE , duplicateGeoms = TRUE)

# Check to make sure it worked
nrow(claims_withshapes_ruralsub@data)
nrow(claims_countycoords_neb)

# Now we have the county polygons to serve as the bounding boxes for the randomly allocated syntehtic farms

```

##################### Loop through each claims level and generate random farm using the grid-approach: Variable Cell Size

```{r}

set.seed(200)

# Set the function to have two parameters in order to rotate through 
iterate.poly.sf = function(x){
  p = list()
  for(i in 1:nrow(x)){
    # Convert from sp to sf
      x2 <- st_as_sf(x)
    # Convert from sf to sfc to access geometry
      x3 <- st_geometry(x2)
      # Set CRS for projection
    crs <-CRS("+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")
    if (x2[i,]$damagedAcres <= 35) {
    # Create grid over polygon
    grdpoints <- sf::st_make_grid(x3[i], cellsize = .015)
    }
    else if (x2[i,]$damagedAcres > 35 & x2[i,]$damagedAcres <=99) {
    grdpoints <- sf::st_make_grid(x3[i], cellsize = .018)  
    }
    else if (x2[i,]$damagedAcres > 99 & x2[i,]$damagedAcres <=278) {
    grdpoints <- sf::st_make_grid(x3[i], cellsize = .020) 
    }
    else {
    grdpoints <- sf::st_make_grid(x3[i], cellsize = .022)
    }
    # Convert back to sp
    grdpoints_sp <- as(st_geometry(grdpoints), "Spatial")
    # Randomly assign numbers to the cells
    grdpoints_sp$random <- runif(length(grdpoints_sp), min=0, max = 10000)
    # Subet to lowest ID to choose one grid square
    grdpoints_sp_subset <- grdpoints_sp[which.min(grdpoints_sp$random),]
    # Extract ID from newly created polygon
    pid <- sapply(slot(grdpoints_sp_subset, "polygons"), function(x) slot(x, "ID"))
    # Set ID from polygon as rowname for dataframe
    p.df2 <- data.frame(ID=x[i,], row.names = pid) 
    p[[i]] <- SpatialPolygonsDataFrame(grdpoints_sp_subset, p.df2)
  }
  return(do.call(rbind,p))
}

regular <- iterate.poly.sf(claims_withshapes_ruralsub)
names(regular@data) <- substring(names(regular@data), 4)
claims_withshapes_ruralsub <- regular
# writeSpatialShape(regular, "farmpolygons_cellvary")

```

################ Merge in county-level crop concentration data ################
```{r}
##### Import Data
NebCountyCrops <- read.csv('Nebraka County Crop Concentration.csv', header = TRUE, stringsAsFactors = FALSE)

##### Prep Crop Data 
# Subset to annual data 
NebCountyCrops <- NebCountyCrops[NebCountyCrops$Period == "YEAR",]
# Subset to acres planted 
NebCountyCrops <- NebCountyCrops[grep("ACRES PLANTED", NebCountyCrops$Data.Item),]
NebCountyCrops <- NebCountyCrops[!grepl("IRRIGATED", NebCountyCrops$Data.Item),]
NebCountyCrops$Value <- as.numeric(gsub(",","",NebCountyCrops$Value))
NebCountyCrops$Data.Item <- NULL

# Collapse to county level and concatenate crop strings per county
NebCountyCrops <- NebCountyCrops %>%
  mutate(Commodity = str_to_title(Commodity),
         County = str_to_title(County))

NebCountyCrops_collapse <- NebCountyCrops %>%
  group_by(State.ANSI, County.ANSI, County) %>%
  summarise(AllCrops = paste(Commodity, collapse = ", "),
            TotalAcres = sum(Value))

NebCountyCrops_collapse$State.ANSI <- as.character(sprintf("%02d",NebCountyCrops_collapse$State.ANSI))
NebCountyCrops_collapse$County.ANSI <- as.character(sprintf("%02d",NebCountyCrops_collapse$County.ANSI))

colnames(NebCountyCrops_collapse)[3] <- c("Select.County")
colnames(NebCountyCrops_collapse)[1] <- c("STATEFP")

# Merge
FullNebraskaClaims <- sp::merge(claims_withshapes_ruralsub, NebCountyCrops_collapse, by = c('STATEFP','Select.County'), all.x = TRUE, all.y = FALSE, duplicateGeoms = TRUE)
```

Create crop claim binary based on whether the crop claim string falls in collapsed crop concentration string

```{r}
FullNebraskaClaims@data$commName <- as.character(FullNebraskaClaims@data$commName)

FullNebraskaClaims@data <- FullNebraskaClaims@data %>%
    mutate(commName = str_to_title(commName))

FullNebraskaClaims@data$commName <- trimws(FullNebraskaClaims@data$commName)

FullNebraskaClaims@data$CropClaimValid <- ifelse(grepl(FullNebraskaClaims@data$commName, FullNebraskaClaims@data$AllCrops), 1, 0)

```

############################## Import in Insured vs. Uninsured Data ###########

```{r}
setwd("~/Coding Prep")
##### Import Data
NebInsuredCrops <- read.csv('NEIA commodity county.csv', header = TRUE, stringsAsFactors = FALSE)
# Subset to key columns 
NebInsuredCrops <- NebInsuredCrops[,c(1,4,5)]
# Clean FIPS
NebInsuredCrops$stateCode <- as.character(sprintf("%02d", NebInsuredCrops$stateCode))

#Align county names
NebInsuredCrops$countyName <- substr(NebInsuredCrops$countyName,1,nchar(NebInsuredCrops$countyName)-7)

colnames(NebInsuredCrops)

colnames(NebInsuredCrops)[1] <- c("STATEFP")
colnames(NebInsuredCrops)[2] <- c("Select.County")

NebInsuredCrops <- NebInsuredCrops %>%
  mutate(insuredComm = str_to_title(insuredComm))

# Merge
FullNebraskaClaims <- sp::merge(FullNebraskaClaims, NebInsuredCrops, by = c('STATEFP','Select.County'), all.x = TRUE, all.y = FALSE, duplicateGeoms = TRUE)

```

Create Insured vs Uninsured binary

```{r}

FullNebraskaClaims@data$CroInsured <- ifelse(grepl(FullNebraskaClaims@data$commName, FullNebraskaClaims@data$insuredComm), 1, 0)

View(FullNebraskaClaims@data)
```

################ Merging in  H5 Soil Moisture

# Testing with one file 
```{r}
#First, letâ€™s load the required libraries.
# Set up
# install.packages('BiocManager')
library(BiocManager)
library(raster)
library(rhdf5)
library(rgdal)
# install.packages('h5')
library(h5)
```

``` {r}
# install.packages('smapr')
library(smapr)

```

``` {r}
# Must create account at https://earthdata.nasa.gov/
# Then enter your username and password in Renviron with:
# set_smap_credentials("[username]", "[password]")

```

``` {r}
available_data <- find_smap(id = 'SPL4SMAU', dates = '2019-03-20', version = 4)
str(available_data)

```

``` {r}
local_files <- download_smap(available_data, overwrite = FALSE, verbose = FALSE)
```

``` {r}
list_smap(local_files[1, ])
sm_raster <- extract_smap(local_files, '/Analysis_Data/sm_rootzone_analysis')
```

``` {r}
plot(sm_raster)
```

``` {r}
co_extent <- extent(c(-104, -95, 39.996, 42.996))
co_extent <- as(co_extent, "SpatialPolygons")
sp::proj4string(co_extent) <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
co_extent

proj_co_extent <- spTransform(co_extent, crs(sm_raster))
co_soil_moisture <- crop(sm_raster, proj_co_extent)

# writeRaster(co_soil_moisture, "nebraska_full", bylayer= FALSE, format = "raster", overwrite = TRUE)
```

Mean for one day for raster layer

``` {r}
mean_sm <- calc(co_soil_moisture, fun = mean)
```

Use all of the data - this creates the layer we use for the flood polygon in Tableau
``` {r}
Full_flood = mean_sm %>%
  rasterToPolygons() %>%
  st_as_sf()

st_write(Full_flood, "Full_flood.shp")

write.csv(Full_flood, "Full_flood_values.csv")

```

Cutting the data to create an "In the high impact flood zone indicator"

``` {r}
#install.packages('igraph')
library(igraph)

sm_cutoff <- mean_sm
sm_cutoff[sm_cutoff < .341] <- NA

sm_cut_polys = sm_cutoff %>% 
  clump() %>%
  rasterToPolygons() %>%
  st_as_sf()

sm_cut_polygroup = sm_cut_polys %>%
  group_by(clumps) %>%
  summarize()

plot(sm_cut_polygroup)

st_write(sm_cut_polygroup, "flood_polygon_2.shp")

```

Calculate Intersection of Flood Layers with Farm Polygons - Using the Clumped Cut (i.e. high impact flood zone)

``` {r}
# Convert farm polygon set to sf
FullNebraskaClaims_sf <- st_as_sf(FullNebraskaClaims) 

st_crs(sm_cut_polygroup)
st_crs(FullNebraskaClaims_sf)

FullNebraskaClaims_sf <- FullNebraskaClaims_sf %>%
  st_transform("+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs")

FullNebraskaClaims_sf <- FullNebraskaClaims_sf %>%
  mutate(FloodPath = as.numeric(st_within(.$geometry, st_union(sm_cut_polygroup$geometry), FALSE)))
colnames(FullNebraskaClaims_sf)

# st_write(FullNebraskaClaims_sf, "FullNebraska_WithWeather_101019.shp")
# 
# write.csv(FullNebraskaClaims_sf, "FullNebraska_WithWeather_101019.csv")  

```

Calculate Intersection of Flood Layers with Farm Polygons - Using the Full Polygonized Raster Layer with a soil moisture level for each point

``` {r}
# Align projections
FullNebraskaClaims_sf <- FullNebraskaClaims_sf %>%
  st_transform("+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs")

# Create index to merge
FullNebraskaClaims_sf$index <- 1:nrow(FullNebraskaClaims_sf)

# Extract the intersecting averages
v <- extract(mean_sm, FullNebraskaClaims_sf, fun=mean, df=TRUE)
FullNebraskaClaims_sf <-  merge(FullNebraskaClaims_sf, v, by.x = "index", by.y = "ID")

colnames(FullNebraskaClaims_sf)[57] <- "mean_sm"
View(FullNebraskaClaims_sf)

st_write(FullNebraskaClaims_sf, "FullNebraska_WithSM_101519.shp")

write.csv(FullNebraskaClaims_sf, "FullNebraska_WithSM_101519.csv")  

```

# End of Farm Polygon and Weather Layer Creation, Intersection, and Analysis ##

######################################################################################### 
Create synthetic data (If needed for modeling)
##########################################################################################
Note: Will go back through and run synthetic data through same grid-based random farm generation 

Note 2: Still subset to Nebraska/Iowa below. Can update based on weather event and Geography later. Note the cleaning for the claims data was done by someone else on the team, so will have to get from them. 

Prep for sampling

```{r message = FALSE}
colnames(claims_nogeo)
# Eliminate non-numeric data
claims_nogeo <- st_drop_geometry(FullNebraskaClaims_sf) 
claims_ss <- claims_nogeo[,c(2,4:5, 10, 13, 15, 19, 21, 24:37, 55:57)]
claims_ss <- sapply(claims_ss, as.numeric)
```

Sample 

```{r message = FALSE}
# We do 10,000 here, but can always do more
claims_synth <- syn(claims_ss, k = 10000, seed = 1)
claims_synth <- claims_synth$syn
```

Merge back in non-numeric labels 

```{r message = FALSE}
claims_synth2 <- claims_synth
colnames(claims_nogeo)

claims_synth2$STATEFP <- as.character(claims_synth2$STATEFP)
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(2,11)]), by = c("STATEFP"))

claims_synth2$County.Fips <- sprintf("%03d",claims_synth2$County.Fips)
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(2,3,5:7, 9, 41:47, 52)]), by = c("County.Fips", "STATEFP"))

claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,13:14]), by = c("commCode"))

claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,15:16]), by = c("insuranceCode"))
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(17,36)]), by = c("coveragecode"))
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(18,37)]), by = c("stagecode"))

# Merge back in the cropclaimvalid part
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(2:3, 51)]), by = c('STATEFP','Select.County'))

claims_synth2$CropClaimValid <- ifelse(grepl(claims_synth2$commName, claims_synth2$AllCrops), 1, 0)


# Merge back in others
claims_nogeo$damageCode <- as.numeric(claims_nogeo$damageCode)
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(19,20)]), by = c("damageCode"))
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(21,22)]), by = c("monthNum"))
claims_synth2 <- left_join(claims_synth2, unique(claims_nogeo[,c(2:3, 54)]), by = c('STATEFP','Select.County'))

```

Align for merge
```{r message = FALSE}
claims_nogeo_sub <- claims_nogeo[,-c(1, 8, 12, 23, 38, 39:40, 48:50)]
claims_synth2_sub <- claims_synth2

full_claims_synth <- rbind(claims_nogeo_sub, claims_synth2_sub)

full_claims_synth$claimID <- 1:nrow(full_claims_synth) 

write.csv(full_claims_synth, "full_claims_synth_101519.csv")
```

Write csv of new data

```{r message = FALSE}

write.csv(claims_synth, "claims_synthetic_100419.csv")

```

##############################################################################
Merge in risk scores from Python-based models
```{r message = FALSE}
setwd("~/USDA/GIS")
FullNebraska <- readOGR("FullNebraska_WithSM_101519.shp")
FullNebraskaRisk <- read.csv("FullNebraska_WithSM_Risk.csv", stringsAsFactors = FALSE)

```

```{r message = FALSE}
colnames(FullNebraska@data)[1] <- "claimID"
FullNebwithRisk <- sp::merge(FullNebraska, FullNebraskaRisk[,c(2,75)], by = c('claimID'), all.x = TRUE, all.y = TRUE)
```

```{r message = FALSE}
FullNebwithRisk@data$risk_cat <- ifelse(FullNebwithRisk@data$risk ==  0.15 | (is.na(FullNebwithRisk@data$risk) & FullNebwithRisk@data$FlodPth == 0), "Low", ifelse(FullNebwithRisk@data$risk == 0.3, "Moderately Low", ifelse(FullNebwithRisk@data$risk == 0.5, "Moderate", ifelse(FullNebwithRisk@data$risk == 0.7, "Moderately High", ifelse(FullNebwithRisk@data$risk == 0.85, "High", 
ifelse(is.na(FullNebwithRisk@data$risk) & FullNebwithRisk@data$FlodPth == 1, "No Risk", NA))))))

FullNebwithRisk@data$risk_cat[is.na(FullNebwithRisk@data$risk_cat)] <- c("No Risk")

View(FullNebwithRisk@data[,58:59])
table(FullNebwithRisk@data$risk_cat)


FullNebwithRisk <- st_as_sf(FullNebwithRisk)
st_write(FullNebwithRisk, "FullNebraska_WithSMandrisk_101619.shp")


writeSpatialShape()

```


#### Adding national level risk scores to national files ############

Prep for sampling
```{r message = FALSE}
# Import in subset claims data 
claims_201819 <- read.csv("20182019allclaims_risk.csv")
table(claims_201819$risk)
table(claims_201819[claims_201819$yearComm == 2019,]$stateName)

claims_201819$risk_cat <- ifelse(claims_201819$risk ==  0.15, "Low", ifelse(claims_201819$risk == 0.3, "Moderately Low", ifelse(claims_201819$risk == 0.5, "Moderate", ifelse(claims_201819$risk == 0.7, "Moderately High", ifelse(claims_201819$risk == 0.85, "High", "No Risk")))))

claims_201819$risk_cat[is.na(claims_201819$risk_cat)] <- c("No Risk")

write.csv(claims_201819, "20182019allclaims_risk_bins.csv")

```

############## Adding in Risk Scores ########################

``` {r}
setwd("~/USDA/GIS")
FullNebraska <- readOGR("FullNebraska_WithSMandRisk_102119.shp")
FullNebraskaRisk <- read.csv("FullNebraska_WithSM_Risk_12062019_1500.csv", stringsAsFactors = FALSE)

colnames(FullNebraska@data)
colnames(FullNebraskaRisk)
```

``` {r message = FALSE}
##### Preprep for merge 
FullNebraska <- FullNebraska[,-c(67:73)]
colnames(FullNebraskaRisk)[73] <- c("totlRsk")
```

```{r message = FALSE}


FullNebwithRisk <- sp::merge(FullNebraska, FullNebraskaRisk[,c(2,67:73)], by = c('claimID'), all.x = TRUE, all.y = TRUE)

FullNebwithRisk <- st_as_sf(FullNebwithRisk)
colnames(FullNebwithRisk)

View(FullNebwithRisk[,c(48:49,74)])
```

``` {r message = FALSE}
# Clean up field names 
colnames(FullNebwithRisk)[42] <- c("LndArk")
colnames(FullNebwithRisk)[43] <- c("LndArm")
colnames(FullNebwithRisk)[44] <- c("WtrArk")
colnames(FullNebwithRisk)[45] <- c("WtrArm")
colnames(FullNebwithRisk)[46] <- c("TtlArk")
colnames(FullNebwithRisk)[47] <- c("TtlArm")
```

``` {r message = FALSE}
st_write(FullNebwithRisk, "FullNebraska_WithSMandrisk_120919.shp")
```
