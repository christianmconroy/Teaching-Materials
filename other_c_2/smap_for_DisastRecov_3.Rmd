---
title: "Flood Claims Fraud Mapping"
author: "Christian Conroy"
date: "03/08/2019"
output: html_document
---

```{r setup, include=FALSE}
require(knitr)
# install.packages('tidyverse')
library(tidyverse)
library(ggplot2)
# install.packages('dplyr')
library(dplyr)
# install.packages('rvest')
library(rvest)
library(rgdal)
library(synthpop)
library(sf)
library(rgeos)
library(maptools)
library(readxl)

opts_chunk$set(echo = TRUE)
options(digits = 3)
opts_knit$set(root.dir ="~/USDA/GIS")
```

################ Merging in  H5 Soil Moisture

# Testing with one file 
```{r}
#First, letâ€™s load the required libraries.
# Set up
# install.packages('BiocManager')
library(BiocManager)
library(raster)
library(rhdf5)
library(rgdal)
# install.packages('h5')
#library(h5)
```

``` {r}
# install.packages('smapr')
library(smapr)

```

``` {r}
# Must create account at https://earthdata.nasa.gov/
# Then enter your username and password in Renviron with:
# set_smap_credentials("[username]", "[password]")

```

``` {r}
available_data <- find_smap(id = 'SPL4SMAU', dates = '2020-06-15', version = 6)
str(available_data)

```

``` {r}
local_files <- download_smap(available_data, overwrite = FALSE, verbose = FALSE)
```

``` {r}
list_smap(local_files[1, ])
sm_raster <- extract_smap(local_files, '/Analysis_Data/sm_rootzone_analysis')
```

``` {r}
plot(sm_raster)
```

################ Clipping to Dead Trees Classifier Extent

``` {r}
co_extent <- extent(c(77.0239, 78.4729, 41.54609, 41.68859))
co_extent <- as(co_extent, "SpatialPolygons")
sp::proj4string(co_extent) <- "+proj=longlat +datum=WGS84 +no_defs"
co_extent
```

``` {r}
proj_co_extent <- spTransform(co_extent,crs(sm_raster))
co_soil_moisture <- crop(sm_raster, proj_co_extent)

# writeRaster(co_soil_moisture, "nebraska_full", bylayer= FALSE, format = "raster", overwrite = TRUE)
```

Mean for one day for raster layer

``` {r}
mean_sm <- calc(co_soil_moisture, fun = mean)
```

``` {r}
plot(mean_sm)
```
``` {r}
output_bucket <- "/Users/christian.conroy/OneDrive - Accenture Federal Services/Documents/Behavioral Analytics/DisastRecov"
writeRaster(mean_sm, filename=paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_final.tif"), overwrite=TRUE)
```

Use all of the data - this creates the layer we use for the flood polygon in Tableau
``` {r}
Full_flood = mean_sm %>%
  rasterToPolygons() %>%
  st_as_sf()

st_write(Full_flood, paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_final_sh.shp"))

write.csv(Full_flood, paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_final_c.csv"))

```

################ Clipping to US

``` {r}
#install.packages('spData')
library(spData)
library(sf)
library(raster)
```

``` {r}
usa    <- spData::us_states %>% sf::st_transform(crs(sm_raster))
hawaii <- spData::hawaii %>% sf::st_transform(crs(sm_raster))
alaska <- spData::alaska %>% sf::st_transform(crs(sm_raster))

#sm_raster_us <- projectRaster(usa,crs = crs(sm_raster))

#sm_raster_us <- projectRaster(sm_raster_us,crs = "+proj=longlat +datum=WGS84") 
```


``` {r}
# crop raster to area of interest and plot (Note that the data downloaded with `raster::getData`
# is split in four subdatasets, so in this case you need to select the correct one.)
usa_smap <- crop(sm_raster, usa)
plot(usa_smap)
plot(sf::st_geometry(usa), add = TRUE)
```


``` {r}
mean_sm <- calc(usa_smap, fun = mean)
plot(mean_sm)

```

``` {r}
output_bucket <- "/Users/christian.conroy/OneDrive - Accenture Federal Services/Documents/Behavioral Analytics/DisastRecov"
writeRaster(mean_sm, filename=paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_usa.tif"), overwrite=TRUE)
```

Use all of the data - this creates the layer we use for the flood polygon in Tableau
``` {r}
Full_flood = mean_sm %>%
  rasterToPolygons() %>%
  st_as_sf()

st_write(Full_flood, paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_usa_sh.shp"))

write.csv(Full_flood, paste0(output_bucket, "/smap_rasters/", "06-15-2020", "_", "smap_cropped_to_usa_c.csv"))

```


### Bring in Wildfire Layers

``` {r}
all_firesf <- readOGR("WFDSSHistoricFirePerimeters_2020/WFDSSHistoricFirePerimeters_2020.shp")  # The st_transform added to this file ensure that both files have same CRS system otherwise it will be impossible to crop. 
usa <- as_Spatial(spData::us_states)

```
``` {r}
# reproject data
all_firesf <- spTransform(all_firesf, crs(usa))
```

``` {r}
# reproject data
plot(usa)
```

``` {r}
# reproject data
plot(all_firesf)
```

``` {r}
all_firesf_coords <- coordinates(all_firesf)
```

- 

``` {r}
plot(usa[1], max.plot = 1, col=NA)
points(all_firesf_coords, pch = 1, col='black', cex = .5)
```

## Bring in Crop Layers (Vector and Tiffs)
``` {r}
install.packages("CropScapeR")
```


``` {r}
library(CropScapeR)
#install.packages('tigris')
library(tigris)
```

``` {r}
us_counties <- read_excel("US_FIPS_CODES.xls", sheet = "3,142 U.S. Counties", skip=1)
us_counties$countfip = paste0(us_counties$`FIPS State`, us_counties$`FIPS County`)
````

``` {r}
year_list = seq(2011,2021,1)
````


#### Per county stats

``` {r}


count_crops <- function(county_list, year_list){
  big_data = data.frame()
  
  for (yee in year_list){
    for (i in county_list$countfip){
      tryCatch({
        data <- GetCDLStat(aoi = i, year = yee, type = 'f')
        data$county_fips = i
        data$year = yee
        big_data <- rbind(big_data,data)
      }, error=function(e){})
    }
  }
  write.csv(big_data, "county_level_crops.csv", row.names = FALSE)
  return(big_data)
}



````


``` {r}
big_data <- count_crops(us_counties, year_list)
head(big_data)

````

``` {r}
big_data_full <- left_join(big_data, us_counties, by = c("county_fips" = "countfip"))
head(big_data_full)
````

``` {r}
write.csv(big_data_full, "county_level_crops_full.csv", row.names = FALSE)
```

# Pixel Level Tiffs

Sample
``` {r}
cdl_IL <- GetCDLData(aoi = 17, year = 2021, type = 'f', save_path = "IL_4.tif")
```

``` {r}
state_cdls <- function(county_list, year_list){
  
  for (yee in year_list){
    for (i in unique(county_list$`FIPS State`)){
      tryCatch({
          cdl_IL <- GetCDLData(aoi = i, year = yee, type = 'f', save_path = paste0("cdl_rasters/", yee, "/", "State_CDL_", i, "_", yee, ".tif"))
      }, error=function(e){})
    }
  }
}
```



``` {r}
state_cdls(us_counties, year_list)
```



