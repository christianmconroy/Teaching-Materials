# tidytext: A tidy way to text mine

## Columns of importance

Numbering the rows allows us to reference them later when we create a document term matrix.

```{r}
tweets_clean <- tweets %>%
  dplyr::select(text, airline_sentiment) %>%
  dplyr::mutate(id = 1:nrow(.))
```

```{r, echo = F}
knitr::kable(head(tweets_clean))
```

## Provide structure to the data

The tidy mantra is:

- Each variable is a column
- Each observation is a row
- Each type of observational unit is a table. 

This translates to text format as a **table with one token per row**

```{r}
tidy_tweets <- tweets_clean %>%
  tidytext::unnest_tokens(word, text ) %>% #tokenizes text
                                           #automatically lowercase and symbols
  dplyr::count(id, word, sort = T) #get counts of words in each tweet
```

```{r, echo = F}
knitr::kable(head(tidy_tweets))
```

Let's take a look at words that are common to the corpus

```{r, eval = F}
tidy_tweets %>%
  dplyr::count(word, sort = T) %>%
  head()
```

```{r, echo = F}
tidy_tweets %>%
  dplyr::count(word, sort = T) %>%
  head() %>%
  knitr::kable()
```

## Clean the Data

There's a lot of cleaning we can do. We can remove *stop words*, we can remove words that are too common or not common enough.

```{r}
uncommon <- tidy_tweets %>%
  dplyr::count(word) %>%
  dplyr::filter(n <= 5)

common_names <- c('united', 
                  'usairways', 
                  'americanair', 
                  'southwestair', 
                  'jetblue',
                  'virginamerica')
```

```{r, message = F}
tidy_tweets <- tidy_tweets %>%
  dplyr::anti_join(tidytext::stop_words) %>%
  dplyr::anti_join(uncommon) %>%
  dplyr::filter(!word %in% common_names) %>%
  dplyr::arrange(desc(n))
  
```


## Create a **Document Term Matrix**

```{r}
tidy_dtm <- tidytext::cast_dtm(tidy_tweets, id, word, n)
```

```{r}
tidy_dtm
```

For computational reasons, it's good to convert the DTM into a sparse matrix.

```{r}
tidy_sparse <- tidy_dtm %>%
  as.matrix() %>%
  Matrix::Matrix(sparse = T)
```

```{r}
tidy_sparse[1:6, 1:6]
```

Now, let's confirm that the rows of the matrix are associated with the number of sentiments we have.

```{r}
nrow(tidy_sparse) == length(tweets_clean$airline_sentiment)
```

This might be shocking, but this is a natural side effect of what happens during the cleaning process. If a document only contained stop words and other words that we filtered out, then it would be removed from the tidy data frame. We can use the **rownames** of the matrix, which are associated with the **id**s of the data frame to pull this information.


```{r}
tidy_y <- tidy_sparse %>%
  rownames() %>%
  as.numeric() %>%
  {tweets_clean$airline_sentiment[.]}
```

```{r}
nrow(tidy_sparse) == length(tidy_y)
```
